{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm import tqdm, trange\n",
    "from more_itertools import chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mntrain = MNIST('../samples')\n",
    "\n",
    "img_tr,lbl_tr = mntrain.load_training()\n",
    "img_ts,lbl_ts = mntrain.load_testing()\n",
    "img_size = 28 # 28x28 pixels\n",
    "\n",
    "def display_image(img):\n",
    "    plt.imshow(np.array(img).reshape(img_size,img_size), cmap=plt.cm.binary)\n",
    "    plt.gcf().axes[0].set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def d_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "def d_sig(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "        self.nodes = np.zeros(length)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Layer: length: %d\" % (self.length)\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def __getitem__(self, index):\n",
    "        return self.nodes[index]\n",
    "    def __setitem__(self, index, value):\n",
    "        self.nodes[index].value = value\n",
    "    def __iter__(self):\n",
    "        return iter(self.nodes)\n",
    "    def __len__(self):\n",
    "        return len(self.nodes)\n",
    "    def __contains__(self, item):\n",
    "        return item in self.nodes\n",
    "    \n",
    "    def get_values(self):\n",
    "        return self.nodes\n",
    "    def set_values(self, values):\n",
    "        self.nodes = np.array(values)\n",
    "    values = property(get_values, set_values)\n",
    "\n",
    "    \n",
    "class Neurons:\n",
    "    def __init__(self, input: Layer, output: Layer):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.weights = np.random.rand(len(output), len(input))*0.2-0.1\n",
    "        self.biases = np.random.rand(len(output))*0.2-0.1\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Layer_Connection: layer1: %s, layer2: %s, weights: %s, biases: %s\" % (len(self.input), len(self.output), self.weights.shape, self.biases.shape)\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def __getitem__(self, index):\n",
    "        return self.weights[index]\n",
    "    def __setitem__(self, index, value):\n",
    "        self.weights[index] = value\n",
    "    def __iter__(self):\n",
    "        return iter(self.weights)\n",
    "    def __len__(self):\n",
    "        return self.weights.shape[0] * self.weights.shape[1]\n",
    "    def __contains__(self, layer):\n",
    "        return layer in (self.input, self.output)\n",
    "\n",
    "\n",
    "class Neural_Network:\n",
    "    def __init__(self, input_size, output_size,hidden_size, hidden_layers=1, batch_size=1):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.layers = [Layer(input_size)]\n",
    "        self.layers.extend([Layer(hidden_size) for _ in range(hidden_layers)])\n",
    "        self.layers.append(Layer(output_size))\n",
    "        \n",
    "        self.neurons = [Neurons(self.layers[i], self.layers[i+1]) for i in range(len(self.layers)-1)][::-1]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Neural_Network: input_size: %d, hidden_size: %d, output_size: %d, hidden_layers: %d, layers: %s, connections: %s\" % (self.input_size, self.hidden_size, self.output_size, len(self.layers)-2, self.layers, self.neurons)\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "        \n",
    "    def output_vector(self):\n",
    "        return self.layers[-1].values\n",
    "    \n",
    "    def output(self):\n",
    "        return np.argmax(self.output_vector())\n",
    "    \n",
    "    def feed_forward(self, image):\n",
    "        self.layers[0].values = np.array(image)/256\n",
    "        neurs = self.neurons[::-1]\n",
    "        for depth, layer in enumerate(self.layers[1:]):\n",
    "            layer.values = sigmoid(np.dot(neurs[depth].weights, self.layers[depth]) + neurs[depth].biases)\n",
    "            \n",
    "\n",
    "    def back_propagate(self, images, labels, factor):\n",
    "        label_arrays = [np.zeros(self.output_size) for _ in range(len(labels))]\n",
    "        for i,label in enumerate(labels):\n",
    "            label_arrays[i][label] = 1\n",
    "            \n",
    "        total_nabla_w = [np.zeros(neuron.weights.shape) for neuron in self.neurons]\n",
    "        total_nabla_b = [np.zeros(neuron.biases.shape) for neuron in self.neurons]\n",
    "        for i in range(len(images)):\n",
    "            nabla_w, nabla_b = self.back_propagate_single(images[i], label_arrays[i])\n",
    "            for j in range(len(nabla_w)):\n",
    "                total_nabla_w[j] += nabla_w[j]\n",
    "                total_nabla_b[j] += nabla_b[j]\n",
    "            \n",
    "        for i in range(len(self.neurons)):\n",
    "            self.neurons[i].weights += factor * total_nabla_w[i]/len(images)\n",
    "            self.neurons[i].biases += factor * total_nabla_b[i]/len(images)\n",
    "        \n",
    "    def back_propagate_single(self, image, label):\n",
    "        self.feed_forward(image)\n",
    "        nabla_w = []\n",
    "        nabla_b = []\n",
    "        for i in range(len(self.neurons)):\n",
    "            neuron = self.neurons[i]\n",
    "            if i == 0: #output layer\n",
    "                delta = np.array(neuron.output.values - label) * np.array(d_sig(neuron.output.values))\n",
    "            else:\n",
    "                delta = np.matmul(self.neurons[i-1].weights.T, delta) * d_sig(neuron.output.values)\n",
    "            delta_w = np.outer(delta, neuron.input.values)\n",
    "            nabla_w.append(delta_w)\n",
    "            nabla_b.append(delta)\n",
    "        return nabla_w, nabla_b\n",
    "\n",
    "    \n",
    "    def test(self, images, labels):\n",
    "        correct = 0\n",
    "        for i in trange(len(images)):\n",
    "            self.feed_forward(images[i])\n",
    "            if self.output() == labels[i]:\n",
    "                correct += 1\n",
    "        return correct/len(images)\n",
    "\n",
    "              \n",
    "    def train(self, images, labels, epochs=1, factor=0.1):\n",
    "        img_lbls = list(zip(images,labels))\n",
    "        for _ in trange(epochs):\n",
    "            np.random.shuffle(img_lbls)\n",
    "            batches = chunked(img_lbls, self.batch_size)\n",
    "            for batch in tqdm(batches, leave=False, desc=\"Epoch\", total = len(images)//self.batch_size):\n",
    "                batch_images = [image for image,_ in batch]\n",
    "                batch_labels = [label for _,label in batch]\n",
    "                self.back_propagate(batch_images, batch_labels, factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Neural_Network(784, 10, 16, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nn.feed_forward(img_ts[2])\n",
    "# for i in nn.layers:\n",
    "#     print(i.values)\n",
    "# print(sigmoid(np.matmul(nn.neurons[-1].weights,nn.layers[0]) + nn.neurons[-1].biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [28:44<00:00, 17.24s/it]\n"
     ]
    }
   ],
   "source": [
    "nn.train(img_tr,lbl_tr, 100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4343.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0794"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.test(img_ts,lbl_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
