### Creating a Neural Network from Scratch (MNIST Dataset)

This is a simple neural network that I created from scratch using only numpy and basic first principles. The network is trained on the MNIST dataset. The network is a 3 layer neural network with 784 input neurons, 100 hidden neurons and 10 output neurons. The network uses the sigmoid activation function or ReLU and the Mean Square Error loss function. The network is trained using stochastic gradient descent with a learning rate of 0.1. The network is trained for 30 epochs.